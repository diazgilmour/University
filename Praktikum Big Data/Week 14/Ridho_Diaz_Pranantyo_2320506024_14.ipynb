{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e2a030e3",
      "metadata": {
        "id": "e2a030e3"
      },
      "source": [
        "# Hands-On Pertemuan 14: Advanced Machine Learning using Spark MLlib"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099562db",
      "metadata": {
        "id": "099562db"
      },
      "source": [
        "## Objectives:\n",
        "- Understand and implement advanced machine learning tasks using Spark MLlib.\n",
        "- Build and evaluate models using real-world datasets.\n",
        "- Explore techniques like feature engineering and hyperparameter tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77df771a",
      "metadata": {
        "id": "77df771a"
      },
      "source": [
        "## Introduction to Spark MLlib\n",
        "Spark MLlib is a scalable library for machine learning that integrates seamlessly with the Spark ecosystem. It supports a wide range of tasks, including regression, classification, clustering, and collaborative filtering."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyspark"
      ],
      "metadata": {
        "id": "9B-hIqsy503h"
      },
      "id": "9B-hIqsy503h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d9ae225b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9ae225b",
        "outputId": "fb55373f-ce60-4cd0-905e-5754db9f9d20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [0.9999999999999992]\n",
            "Intercept: 15.000000000000009\n"
          ]
        }
      ],
      "source": [
        "# Example: Linear Regression with Spark MLlib\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Initialize Spark Session\n",
        "spark = SparkSession.builder.appName('MLlib Example').getOrCreate()\n",
        "\n",
        "# Load sample data\n",
        "data = [(1, 5.0, 20.0), (2, 10.0, 25.0), (3, 15.0, 30.0), (4, 20.0, 35.0)]\n",
        "columns = ['ID', 'Feature', 'Target']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Prepare data for modeling\n",
        "assembler = VectorAssembler(inputCols=['Feature'], outputCol='Features')\n",
        "df_transformed = assembler.transform(df)\n",
        "\n",
        "# Train a linear regression model\n",
        "lr = LinearRegression(featuresCol='Features', labelCol='Target')\n",
        "model = lr.fit(df_transformed)\n",
        "\n",
        "# Print model coefficients\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Example dataset\n",
        "data = [(1, 2.0, 3.0, 0), (2, 1.0, 5.0, 1), (3, 2.5, 4.5, 1), (4, 3.0, 6.0, 0)]\n",
        "columns = ['ID', 'Feature1', 'Feature2', 'Label']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Use VectorAssembler to change features columns to a vector\n",
        "assembler = VectorAssembler(inputCols=['Feature1', 'Feature2'], outputCol='Features')\n",
        "\n",
        "# Transform the data\n",
        "df = assembler.transform(df)\n",
        "\n",
        "# Train logistic regression model\n",
        "lr = LogisticRegression(featuresCol='Features', labelCol='Label')\n",
        "model = lr.fit(df)\n",
        "\n",
        "# Display coefficients and summary\n",
        "print(f'Coefficients: {model.coefficients}')\n",
        "print(f'Intercept: {model.intercept}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EAL1ocV6Fs5",
        "outputId": "200eca6e-761e-4b78-a8f2-1214d9d248d0"
      },
      "id": "6EAL1ocV6Fs5",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coefficients: [-12.262057929180484,4.087352266486688]\n",
            "Intercept: 11.56891272665312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.clustering import KMeans\n",
        "from pyspark.ml.linalg import Vectors\n",
        "\n",
        "# Example dataset\n",
        "data = [(1, Vectors.dense([1.0, 1.0])), (2, Vectors.dense([5.0, 5.0])), (3, Vectors.dense([10.0, 10.0])), (4, Vectors.dense([15.0, 15.0]))]\n",
        "columns = ['ID', 'Features']\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "# Train KMeans clustering model\n",
        "kmeans = KMeans(featuresCol='Features', k=2)\n",
        "model = kmeans.fit(df)\n",
        "\n",
        "# Show cluster centers\n",
        "centers = model.clusterCenters()\n",
        "print(f'Cluster Centers: {centers}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-I5p1Kn6WtX",
        "outputId": "237a33ec-c7f4-4075-a786-323271866406"
      },
      "id": "Q-I5p1Kn6WtX",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cluster Centers: [array([5.33333333, 5.33333333]), array([15., 15.])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a60a8d7e",
      "metadata": {
        "id": "a60a8d7e"
      },
      "source": [
        "## Homework\n",
        "- Load a real-world dataset into Spark and prepare it for machine learning tasks.\n",
        "- Build a classification model using Spark MLlib and evaluate its performance.\n",
        "- Explore hyperparameter tuning using cross-validation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Homework 1"
      ],
      "metadata": {
        "id": "hGGdPRvX8R7G"
      },
      "id": "hGGdPRvX8R7G"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Initialize a Spark session\n",
        "spark = SparkSession.builder.appName(\"StockPriceClassification\").getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"Uniqlo.csv\"\n",
        "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "# Show the schema to understand the structure of the data\n",
        "data.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5VPaHMuDzIH",
        "outputId": "70db41a8-36e9-4ff0-ebaf-97f98848c748"
      },
      "id": "s5VPaHMuDzIH",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Open: integer (nullable = true)\n",
            " |-- High: integer (nullable = true)\n",
            " |-- Low: integer (nullable = true)\n",
            " |-- Close: integer (nullable = true)\n",
            " |-- Volume: integer (nullable = true)\n",
            " |-- Stock Trading: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Homework 2"
      ],
      "metadata": {
        "id": "jC-owDZw9SbH"
      },
      "id": "jC-owDZw9SbH"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lag, col\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "# Mendefinisikan window spec untuk mendapatkan nilai lag dari kolom Close\n",
        "windowSpec = Window.orderBy(\"Date\")\n",
        "\n",
        "# Membuat kolom Label berdasarkan harga penutupan hari sebelumnya\n",
        "data = data.withColumn(\"prev_Close\", lag(\"Close\").over(windowSpec))\n",
        "data = data.withColumn(\"Label\", (col(\"Close\") > col(\"prev_Close\")).cast(\"integer\"))\n"
      ],
      "metadata": {
        "id": "yaq2WhgtFXCX"
      },
      "id": "yaq2WhgtFXCX",
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "# Menggunakan VectorAssembler untuk menggabungkan kolom yang diinginkan menjadi kolom features\n",
        "assembler = VectorAssembler(inputCols=[\"Open\", \"High\", \"Low\", \"Volume\"], outputCol=\"features\")\n",
        "data = assembler.transform(data)\n"
      ],
      "metadata": {
        "id": "bpFeqP2iFZLh"
      },
      "id": "bpFeqP2iFZLh",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghapus baris yang memiliki nilai null di kolom Label dan features\n",
        "data = data.filter(data['Label'].isNotNull() & data['features'].isNotNull())\n"
      ],
      "metadata": {
        "id": "HED71XFBFeWo"
      },
      "id": "HED71XFBFeWo",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi data menjadi data pelatihan dan pengujian (80% train, 20% test)\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=1234)"
      ],
      "metadata": {
        "id": "salQFO7HFwRV"
      },
      "id": "salQFO7HFwRV",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat model klasifikasi dengan Logistic Regression\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Label\")\n",
        "\n",
        "# Melatih model dengan data pelatihan\n",
        "model = lr.fit(train_data)\n"
      ],
      "metadata": {
        "id": "4LmIi81vFzZs"
      },
      "id": "4LmIi81vFzZs",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat prediksi menggunakan data uji\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Menampilkan beberapa hasil prediksi\n",
        "predictions.select(\"Date\", \"Label\", \"prediction\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tc-7789hF4J4",
        "outputId": "09612fea-7de6-4510-c485-76097b3c3390"
      },
      "id": "tc-7789hF4J4",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----+----------+\n",
            "|      Date|Label|prediction|\n",
            "+----------+-----+----------+\n",
            "|2012-01-06|    1|       0.0|\n",
            "|2012-01-12|    0|       0.0|\n",
            "|2012-02-06|    1|       1.0|\n",
            "|2012-02-09|    0|       0.0|\n",
            "|2012-02-10|    0|       0.0|\n",
            "+----------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi model\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"Label\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Model Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lgw0gB_F7wt",
        "outputId": "1167d28e-3191-419a-9631-d453277bc475"
      },
      "id": "9lgw0gB_F7wt",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.7779\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Homework 3"
      ],
      "metadata": {
        "id": "2K3qNwcjGBpw"
      },
      "id": "2K3qNwcjGBpw"
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
      ],
      "metadata": {
        "id": "RpRnbQsCGidY"
      },
      "id": "RpRnbQsCGidY",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi data menjadi training dan test set\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=1234)\n",
        "\n",
        "# Memeriksa ukuran data training dan testing\n",
        "print(f\"Training Data: {train_data.count()} rows\")\n",
        "print(f\"Test Data: {test_data.count()} rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KayX4yIrGDgO",
        "outputId": "15dade07-1d82-4370-d3a4-e8c0b16fcf27"
      },
      "id": "KayX4yIrGDgO",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data: 981 rows\n",
            "Test Data: 244 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat model Logistic Regression\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='Label')\n",
        "\n",
        "# Mendefinisikan evaluator untuk model klasifikasi\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"Label\")\n",
        "\n",
        "# Membuat parameter grid untuk tuning hyperparameter\n",
        "param_grid = (ParamGridBuilder()\n",
        "              .addGrid(lr.regParam, [0.1, 0.01])\n",
        "              .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "              .build())\n",
        "\n",
        "# Membuat cross-validation untuk tuning model\n",
        "cv = CrossValidator(estimator=lr,\n",
        "                    estimatorParamMaps=param_grid,\n",
        "                    evaluator=evaluator,\n",
        "                    numFolds=3)  # 3-fold cross-validation\n"
      ],
      "metadata": {
        "id": "5x4hZpxbGbq_"
      },
      "id": "5x4hZpxbGbq_",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan data pelatihan\n",
        "cv_model = cv.fit(train_data)\n",
        "\n",
        "# Menyimpan model hasil cross-validation\n",
        "cv_model.save(\"model\")\n",
        "\n",
        "# Membuat prediksi menggunakan model terbaik\n",
        "predictions = cv_model.transform(test_data)\n",
        "\n",
        "# Menampilkan beberapa prediksi\n",
        "predictions.select(\"features\", \"Label\", \"prediction\").show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elIpilTjGobC",
        "outputId": "06b4d110-f942-4719-d117-09dcb9e96220"
      },
      "id": "elIpilTjGobC",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+----------+\n",
            "|            features|Label|prediction|\n",
            "+--------------------+-----+----------+\n",
            "|[13990.0,14030.0,...|    1|       1.0|\n",
            "|[14520.0,14600.0,...|    0|       1.0|\n",
            "|[15600.0,15830.0,...|    1|       1.0|\n",
            "|[15900.0,15910.0,...|    0|       1.0|\n",
            "|[15680.0,15680.0,...|    0|       1.0|\n",
            "+--------------------+-----+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi model menggunakan AUC (Area Under Curve)\n",
        "auc = evaluator.evaluate(predictions)\n",
        "print(f\"AUC: {auc}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7n9z1maH3OF",
        "outputId": "4cf2d42a-3961-4f9e-dac6-3adf5a305c00"
      },
      "id": "X7n9z1maH3OF",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC: 0.5394383230314432\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}